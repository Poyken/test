"""
AI Flow - Reflector Agent
Critiques and suggests improvements for generated code
"""

import json
from agents.base_agent import BaseAgent
from orchestrator.state import WorkflowState, TaskStatus

class ReflectorAgent(BaseAgent):
    """
    Reflector Agent
    
    Responsibilities:
    - Review generated code against requirements
    - Check for potential bugs and security issues
    - Verify adherence to coding standards
    - Provide specific feedback for improvements
    """
    
    @property
    def name(self) -> str:
        return "Reflector Agent"
    
    @property
    def system_prompt(self) -> str:
        return """You are a Principal Software Engineer acting as a Code Referee.
Your job is to critically review code generated by other agents BEFORE it goes to human review.

REVIEW CRITERIA:
1. Correctness: Does the code solve the task?
2. Safety: Are there security vulnerabilities?
3. Quality: Is the code clean, typed, and well-structured?
4. Completeness: Are all required files present?

OUTPUT FORMAT:
Respond with a JSON object:
{
  "status": "approved" | "needs_revision",
  "feedback": "Detailed explanation of what needs to be fixed... (if needs_revision)",
  "score": 0-100 (quality score)
}

CRITICAL:
- Be strict but fair.
- If code is good, approve it (status: "approved").
- If code has compilation errors or major logic flaws, reject it (status: "needs_revision").
- Minor style issues can be suppressed if the code is functional.
- Respond with ONLY valid JSON.
"""

    async def process(self, state: WorkflowState) -> WorkflowState:
        """Review recent code generation"""
        current_task_id = state.get("current_task_id")
        
        if not current_task_id:
            return state
            
        # Find task
        task = next((t for t in state["tasks"] if t.id == current_task_id), None)
        if not task:
            return state
            
        # Get generated content
        if not task.generated_code:
            self.log("No code to review", "warning")
            return state
            
        files_data = json.loads(task.generated_code)
        
        # Prepare context for LLM
        code_context = ""
        for f in files_data:
            code_context += f"\n=== {f['path']} ===\n{f['content']}\n"
            
        user_prompt = f"""Review the following code for Task: {task.title}
        
DESCRIPTION:
{task.description}

GENERATED CODE:
{code_context}

Provide your critique in JSON format.
"""

        try:
            response = await self.invoke_llm(user_prompt)
            
            # Parse response
            import re
            json_match = re.search(r'\{.*\}', str(response), re.DOTALL)
            if json_match:
                result = json.loads(json_match.group(0))
                
                # Update state with feedback
                state["reflector_feedback"] = result
                
                if result.get("status") == "needs_revision":
                    self.log(f"Reflector rejected code: {result.get('feedback')[:100]}...", "warning")
                    # We don't change task status here; the orchestrator handles the transition
                else:
                    self.log(f"Reflector approved code (Score: {result.get('score')})", "success")
            else:
                self.log("Failed to parse Reflector response", "error")
                
        except Exception as e:
            self.log(f"Reflector error: {e}", "error")
            
        return state
